{% extends 'block1.html' %}

  {% block info %}
    <div class="container mt-4">
      <h1>Блок 2</h1>
      <p>1. Опишем главные принципы пользования сервисом и разъясним смысл его настроек, вынесенных в управление пользователем.</p>

      <p>1.1. Формат входных данных: файл *.csv или *.xls(x), содержащий столбцы: ID - как обязательное поле, с уникальными целочисленными значениями; и произвольное количество полей, для числовых значений координат { разделитель десятичной части : «.» }, которыми описываются анализируемые данные.<a href="#">Пример фала можно получить здесь.</a></p>

      <p>Таким образом, если стоит задача обработки датасета, включающего в себя неколичественные данных (пол, цвет, «да/нет» и т.п.) то наряду с прочими требованиями ко входному формату, такие данные необходимо представить их в числовом виде.</p>

      <p>Входной файл, содержащий отдельные невалидные записи (например, записи с отсутствующим id, или содержащие значения не соответствующие разрешенному формату) принимается алгоритмом в работу, благодаря встроенной предварительной проверке, - невалидные записи исключаются из дальнейшей обработки с выводом соответствующего уведомления.</p>

      <p>Количество валидных записей (строк) данных должно составлять не менее 10 (десяти).</p>

      <p>TRAIN - это данные в отдельном файле (часть данных в общем исходном файле) к которым применяются процедуры кластеризации/выявления выпуклых множеств/классификации;</p>

      <p>TEST - так же данные в отдельном файле (часть данных в общем исходном файле) к которым применяются процедура классификации – т.е. отнесения по унарному или множественному принципу к множеству(классу) определенному заранее;</p>

      <p>Получение TRAIN и TEST может быть реализовано двумя способами: - непосредственной загрузкой двух файлов при создании Проекта; - загрузкой единственного файла, с последующим применением опции «%-выборки» - вводится значение в диапазоне (открытого типа) от 0 до 100 , в соответствии с которым производится <b>случайная</b> выборка указанного процента точек данных, которая относится в <b>train</b>-выборку (для применения к ней процедур кластеризации - обычной, и/или «convex, и по их итогам – классификации). Соответственно – остальная часть точек автоматически записывается в «test», к которой может быть применена <b>только классификация</b>, использующая результаты, полученные на анализе <b>train</b>-выборки. </p>
      
      <p>Важное замечание о требованиях к соответствию «датасетов» TRAIN и TEST : как уже говорилось - оба они имеют обязательное поле целочисленных ID и ненулевой, конечный набор полей координат. Кроме этого, TRAIN и TEST должны иметь <b>минимум одно общее поле координат</b> - иначе говоря, хотя бы один из заголовков Координат в данных TEST должен содержаться и в данных TRAIN. </p>
      <p>То, что требование ограничивается тем, что данные TRAIN и TEST не обязательно должны быть описаны в одной и той же системе координат, а могут быть описаны и в разных системах, от которых необходимо и достаточно лишь минимальное пересечение наборов измерений, составляет важное обстоятельство, благодаря которому возможности предлагаемого здесь аналитического инструмента значительно расширяются. Суть этого будет ясна из дальнейших комментариев.</p>
      <p>1.2. Продолжим в привязке к разъяснению остальных настроек, которые требуются, что бы начать работу с Сервисом.</p>
      <p>- Создан проект, данные загружены в виде одного или сразу двух (train/test) файлов, и имеется возможность просмотра этих данных. (Рис .х...)</p>
      <p>Кроме этого, становится виден перечень координат train-данных с возможностью их частичного исключения из анализа в процессе выполнения алгоритмов кластеризации (- обычной, и/или «convex»).</p>
      <p>- Далее пользователю предлагается применить к данным процедуру, реализующую Метод главных компонент (principal component analysis, PCA) с целью устранения линейной зависимости между исходными координатами. И соответственно – так же представляется возможность исключить из обработки часть координат. По выполнении PCA, координаты, включенные в расчет заменяется их линейными комбинациями, в количестве, равном количеству исходных координат. Линейные коэффициенты сохраняются, возврат к исходным координатам может быть выполнен по завершению анализа. </p>
      <p>Выполнив PCA, либо пропустив его, выполняем нормирование координат (это необходимый этап) для этого задаем значение настроек % минимальных расстояний (или жмем «определить автоматически) и «макс. допустимый процент нулевых расстояний». </p>
      <p>Нормирование в данном алгоритме выполняется делением исходных всех значений по координате, на среднеарифметическое от процента минимальных расстояний, взятых из матрицы евкл.расстояний, рассчитанной по каждой из координат отдельно. Отбор процента минимальных, таким образом, являет собой робастную сортировку - определение «ядра» наиболее тесно расположенных (по конкретно взятому измерению) точек данных и исключение выбросов, - сильно рассеянной части выборки. Вторая настройка регулирует допустимый процент попадания нулевых расстояний (которые вполне могут иметься в данных и составлять в них значительную долю) в базу расчета нормы, во избежание ее нулевого значения (которое сделает невозможной дальнейшую корректную работу).</p>
    </div>
  {% endblock %}