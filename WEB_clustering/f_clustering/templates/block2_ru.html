{% extends 'block1_ru.html' %}

  {% block info %}
    <div class="container mt-4">

      {% load static %}

      <h1>Блок 2</h1>
      <p>1. Опишем главные принципы пользования сервисом и разъясним смысл его настроек, вынесенных в управление пользователем.</p>

      <p>1.1. Формат входных данных: файл *.csv или *.xls(x), содержащий столбцы: id (регистр важен) - как обязательное поле, с уникальными целочисленными значениями; и произвольное количество полей, для числовых значений координат (название каждого такого поля - X1, X2, X3 и т.д.; разделитель десятичной части : «.» или ","), которыми описываются анализируемые данные.<a href="https://disk.yandex.ru/i/a4W5mmOh103R4A"> Пример файла можно получить здесь.</a></p>

      <p>Таким образом, если стоит задача обработки датасета, включающего в себя неколичественные данные (пол, цвет, «да/нет» и т.п.), либо количественные по природе, но задаваемые в формате, отличном от числового  (дата/время и др.), то наряду с прочими требованиями к входному формату, такие данные необходимо представить в числовом виде.</p>

      <p>Входной файл подвергается предварительной проверке:</p>
      <ul>
        <li>Размер входного файла не должен превышать 4 Мб</li>
        <li>Количество строк данных не более 2000 и менее 10</li>
        <li>Количество полей координат не более 50 и не менее 1</li>
        <li>Наличие поля id и уникальность значений в нём </li>
        <li>Поле id стоит первым</li>
        <li><b>Столбцы не содержат нечисловых символов</b></li>
      </ul>
      <hr/>
      <p>Данные  обрабатываются сервисом в двух   качествах:  как train –выборка  и как  test- выборка.</p>
      <p>TRAIN - это данные в отдельном файле (часть данных в общем исходном файле) к которым применяются процедуры кластеризации/выявления выпуклых множеств/классификации;</p>

      <p>TEST - так же данные в отдельном файле (часть данных в общем исходном файле) к которым применяются процедура классификации – т.е. отнесения по унарному или множественному принципу к множеству(классу) определенному заранее;</p>

      <p>С точки зрения  формата записи данные указанных  категорий ничем не различаются, - речь идет о чисто смысловом, логическом разграничении.</p>

      <p>Определение классов происходит в результате выполнения на TRAIN реализованных в сервисе алгоритмов кластеризации/выявления выпуклых множеств и получения в итоге «размеченной» (train)-выборки, но в принципе эта разметка может быть реализована любым способом , - может быть выполнена хоть самим пользователем вручную, или сторонним алгоритмом, лишь бы к загружаемому train-файлу были соблюдены все требования</p>

      <p>Получение TRAIN и TEST может быть реализовано двумя способами: - непосредственной загрузкой двух файлов при создании Проекта; - загрузкой единственного файла, с последующим применением опции «%-выборки» - вводится значение в диапазоне (открытого типа) от 0 до 100 , в соответствии с которым производится <b>случайная</b> выборка указанного процента точек данных, которая относится в <b>train</b>-выборку (для применения к ней процедур кластеризации - обычной, и/или «convex, и по их итогам – классификации). Соответственно – остальная часть точек автоматически записывается в «test», к которой может быть применена <b>только классификация</b>, использующая результаты, полученные на анализе <b>train</b>-выборки. </p>

      <p>Важное замечание о требованиях к соответствию «датасетов» TRAIN и TEST : как уже говорилось - оба они имеют обязательное поле уникальных целочисленных id и ненулевой, конечный набор полей координат. Кроме этого, TRAIN и TEST должны иметь <b> как минимум одно общее поле координат</b> - иначе говоря, хотя бы один из заголовков X в данных TEST должен содержаться и в данных TRAIN. </p>

      <p>То, что данные TRAIN и TEST не обязательно должны быть описаны в одной и той же системе координат, а могут быть описаны и в разных системах, от которых необходимо и достаточно лишь минимальное пересечение наборов измерений, составляет важное обстоятельство, благодаря которому возможности предлагаемого здесь аналитического инструмента значительно расширяются. Суть этого будет ясна из дальнейших комментариев.</p>

      <p>1.2. Продолжим в привязке к разъяснению остальных настроек, которые требуются, что бы начать работу с Сервисом.</p>

      <p>С помощью меню «Проекты», открываемого нажатием соответствующей кнопки, создаем проект, данные в проект загружаем в виде единственного файла (будет он обрабатываться как train или как test на этапе загрузки не имеет значения – формат одинаков), и имеется возможность просмотра этих данных.</p>

      <figure class="sign">
       <img src="{% static "images/6.png" %}" alt="Рисунок 6 не нейден" height=320>
       <figcaption>Рисунок 6</figcaption>
      </figure>

      <p>Кроме этого, на этом стартовом этапе (вкладка «Начальная страница») становится доступна опция определения Количества интервалов (это понадобится для вывода некоторой статистики) и опция отделения процента train выборки (по умолчанию равен 100%)</p>

      <p>Последовательный переход между этапами выполняется нажатием кнопки "Далее" (внизу экрана, под окном Лога). </p>
      <img src="{% static "images/next.png" %}" alt="Рисунок next не нейден" height=50>

      <p>Произвольный переход между этапами может осуществляться перемещением по соответствующим вкладкам</p>
      <img src="{% static "images/menu.png" %}" alt="Рисунок menu не нейден" height=50>
      <p>при условии, что  конкретный переход (или возврат) к этапу  алгоритмически допустим, с учетом текущего выполненного этапа.</p>

      <p>При переходе на этап «Подбор констант» (реализующий Предварительный этап анализа) пользователю становится виден перечень координат загруженных данных.</p>

      <p>Сначала, пользователю в обязательном порядке нужно выполнить расчет норм (в вариантах «Рассчитать нормы» и «Рассчитать Нормы + РСА» различие между ними будет прокомментировано ниже) - в результате нажатия соотв-щей кнопки нормы для каждой координаты входных данных рассчитываются и выводятся в форме, сами значения координат делятся на их нормы (или, делятся на нормы + преобразуются в соответствии с результатами PCA) и в дальнейшем участвуют в анализе в нормированном виде.</p>

      <p>По выполнении указанного действия, появляется возможность выборочного исключения отдельных координат из дальнейшего анализа (состоящего в выполнении алгоритмов кластеризации - обычной, и/или «convex») а так же, появляется меню для выполнения подбора констант – в частности выбора метода подбора («Базовый»/»Оптимизированный»). По выполнении этапа подбора констант (так же являющегося обязательным), для пользователя становится доступна кнопка «Далее», ведущая на собственно, этап кластеризации.</p>

      <p>Ниже приведем подробности процедур нормирования и PCA: посредством нажатия кнопки «Рассчитать Нормы + РСА» к данным (опционально) применяется процедура, реализующая Метод главных компонент (principal component analysis, PCA) с целью устранения линейной зависимости, существующей между исходными координатами. В рамках предварительной настройки, представляется возможность исключить из обработки часть координат, а точнее – можно осуществить выборочное исключение координат из преобразования по PCA, но нормирование всё равно будет применено ко всем координатам. По выполнении PCA, координаты, включенные в расчет заменяются их линейными комбинациями, в количестве, равном количеству исходных координат. При выводе значений норм, к наименованиям координат, не включенных в PCA будет добавлено «_original». Линейные коэффициенты сохраняются, возврат к исходным координатам может быть выполнен по завершению анализа.</p>

      <p>Перед выполнением нормирования+PCA, либо – одного только нормирования (выбор одного из этих двух вариантов - есть обязательное действие) задаем значение настроек % минимальных расстояний (или, жмем «определить автоматически) и «макс. допустимый процент нулевых расстояний». И нажимаем «Рассчитать нормы». В результате значения всех координат массива данных (а не только, выбранные пользователем для анализа) будут преобразованы в нормированный вид. Внимание: нормы (и компоненты) рассчитываются в рамках Проекта только один раз и их нельзя сбросить и подвергнуть перерасчету, в отличие от параметров, подбор которых следует далее. При этом, их можно скорректировать вручную, с последующим нажатием «Сохранить».</p>

      <p>Нормирование в данном алгоритме выполняется делением всех исходных значений по координате, на среднеарифметическое от заданного процента минимальных расстояний, взятых из матрицы евкл.расстояний, рассчитанной по каждой координате отдельно. Отбор процента минимальных, таким образом, являет собой робастную сортировку, цель которой - определение «ядра» наиболее тесно расположенных (по конкретно взятому измерению) точек данных и исключение влияния выбросов, - т.е., сильно рассеянной части выборки. Вторая настройка регулирует допустимый процент попадания нулевых расстояний (которые вполне могут встречаться в данных и, даже, составлять в них значительную долю) в базу расчета нормы, во избежание возникновения нулевых значений норм (которое сделает невозможной дальнейшую корректную работу).</p>
    </div>
  {% endblock %}